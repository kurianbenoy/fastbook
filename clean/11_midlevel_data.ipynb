{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/kurianbenoy/mambaforge/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "! [ -e /content ] && pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastbook import *\n",
    "from IPython.display import display,HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Munging with fastai's Mid-Level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Going Deeper into fastai's Layered API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.all import *\n",
    "\n",
    "dls = TextDataLoaders.from_folder(untar_data(URLs.IMDB), valid='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB)\n",
    "dls = DataBlock(\n",
    "    blocks=(TextBlock.from_folder(path),CategoryBlock),\n",
    "    get_y = parent_label,\n",
    "    get_items=partial(get_text_files, folders=['train', 'test']),\n",
    "    splitter=GrandparentSplitter(valid_name='test')\n",
    ").dataloaders(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/fastai/torch_core.py:476: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ax = ax.append(pd.Series({label: o}))\n",
      "/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/fastai/torch_core.py:476: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ax = ax.append(pd.Series({label: o}))\n",
      "/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/fastai/torch_core.py:476: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ax = ax.append(pd.Series({label: o}))\n",
      "/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/fastai/torch_core.py:476: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ax = ax.append(pd.Series({label: o}))\n",
      "/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/fastai/torch_core.py:476: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ax = ax.append(pd.Series({label: o}))\n",
      "/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/fastai/torch_core.py:476: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ax = ax.append(pd.Series({label: o}))\n",
      "/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/fastai/torch_core.py:476: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ax = ax.append(pd.Series({label: o}))\n",
      "/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/fastai/torch_core.py:476: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ax = ax.append(pd.Series({label: o}))\n",
      "/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/fastai/torch_core.py:476: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ax = ax.append(pd.Series({label: o}))\n",
      "/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/fastai/torch_core.py:476: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ax = ax.append(pd.Series({label: o}))\n",
      "/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/fastai/torch_core.py:476: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ax = ax.append(pd.Series({label: o}))\n",
      "/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/fastai/torch_core.py:476: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ax = ax.append(pd.Series({label: o}))\n",
      "/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/fastai/torch_core.py:476: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ax = ax.append(pd.Series({label: o}))\n",
      "/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/fastai/torch_core.py:476: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ax = ax.append(pd.Series({label: o}))\n",
      "/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/fastai/torch_core.py:476: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ax = ax.append(pd.Series({label: o}))\n",
      "/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/fastai/torch_core.py:476: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ax = ax.append(pd.Series({label: o}))\n",
      "/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/fastai/torch_core.py:476: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ax = ax.append(pd.Series({label: o}))\n",
      "/home/kurianbenoy/mambaforge/lib/python3.9/site-packages/fastai/torch_core.py:476: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ax = ax.append(pd.Series({label: o}))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos xxmaj match 1 : xxmaj tag xxmaj team xxmaj table xxmaj match xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley vs xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley started things off with a xxmaj tag xxmaj team xxmaj table xxmaj match against xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit . xxmaj according to the rules of the match , both opponents have to go through tables in order to get the win . xxmaj benoit and xxmaj guerrero heated up early on by taking turns hammering first xxmaj spike and then xxmaj bubba xxmaj ray . a xxmaj german xxunk by xxmaj benoit to xxmaj bubba took the wind out of the xxmaj dudley brother . xxmaj spike tried to help his brother , but the referee restrained him while xxmaj benoit and xxmaj guerrero</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxbos i thought that xxup rotj was clearly the best out of the three xxmaj star xxmaj wars movies . i find it surprising that xxup rotj is considered the weakest installment in the xxmaj trilogy by many who have voted . xxmaj to me it seemed like xxup rotj was the best because it had the most profound plot , the most suspense , surprises , most xxunk the ending ) and definitely the most episodic movie . i personally like the xxmaj empire xxmaj strikes xxmaj back a lot also but i think it is slightly less good than than xxup rotj since it was slower - moving , was not as episodic , and i just did not feel as much suspense or emotion as i did with the third movie . \\n\\n xxmaj it also seems like to me that after reading these surprising reviews that</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xxbos xxmaj heavy - handed moralism . xxmaj writers using characters as mouthpieces to speak for themselves . xxmaj predictable , plodding plot points ( say that five times fast ) . a child 's imitation of xxmaj britney xxmaj spears . xxmaj this film has all the earmarks of a xxmaj lifetime xxmaj special reject . \\n\\n i honestly believe that xxmaj jesus xxmaj xxunk and xxmaj julia xxmaj xxunk set out to create a thought - provoking , emotional film on a tough subject , exploring the idea that things are not always black and white , that one who is a criminal by definition is not necessarily a bad human being , and that there can be extenuating circumstances , especially when one puts the well - being of a child first . xxmaj however , their earnestness ends up being channeled into preachy dialogue and trite</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xxbos xxmaj jim xxmaj carrey is back to much the same role that he played in xxmaj the xxmaj mask , a timid guy who is trying to get ahead in the world but who seems to be plagued with bad luck . xxmaj even when he tries to help a homeless guy from being harassed by a bunch of hoodlums ( and of course they have to be xxmaj mexican , obviously ) , his good will towards his fellow man backfires . xxmaj in that case , it was n't too hard to predict that he was about to have a handful of angry hoodlums , but i like that the movie suggests that things like that should n't be ignored . xxmaj i 'm reminded of the episode of xxmaj michael xxmaj moore 's brilliant xxmaj the xxmaj awful xxmaj truth , when they had a man</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xxbos xxmaj god ! xxmaj zorro has been the the subject of about as many movies as xxmaj tarzan , and probably had about as many actors in the title role . \\n\\n xxmaj this xxmaj serial is one of my own personal favourites , and as previously stated , it is one of the xxmaj top 5 xxmaj sound xxmaj serials . xxmaj oddly enough , this is one production that came out in that water shed year of 1939 . * xxmaj by the time of this production in ' 39 , xxmaj zorro was really well known as a ( pulp ) literary and movie character . xxmaj the film opens up with a little foot note about the xxmaj history of the xxmaj mexico 's struggle for freedom from rule by a xxmaj european xxmaj monarchy , namely xxmaj spain . xxmaj the story invites comparison</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xxbos xxmaj to be a xxmaj buster xxmaj keaton fan is to have your heart broken on a regular basis . xxmaj most of us first encounter xxmaj keaton in one of the brilliant feature films from his great period of independent production : ' the xxmaj general ' , ' the xxmaj navigator ' , ' sherlock xxmaj jnr ' . xxmaj we recognise him as the greatest figure in the entire history of film comedy , and we want to see more of his movies . xxmaj here the heartbreak begins . xxmaj after ' steamboat xxmaj bill xxmaj jnr ' , xxmaj keaton 's brother - in - law xxmaj joseph xxmaj xxunk pressured him into signing a contract that put xxmaj keaton under the control of xxup mgm . xxmaj keaton became just one more actor for hire , performing someone else 's scripts . xxmaj</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>xxbos xxmaj how strange the human mind is ; this center of activity wherein perceptions of reality are formed and stored , and in which one 's view of the world hinges on the finely tuned functioning of the brain , this most delicate and intricate processor of all things sensory . xxmaj and how much do we really know of it 's inner - workings , of it 's depth or capacity ? xxmaj what is it in the mind that allows us to discern between reality and a dream ? xxmaj or can we ? xxmaj perhaps our sense of reality is no more than an impression of what we actually see , like looking at a painting by xxmaj monet , in which the vanilla sky of his vision becomes our reality . xxmaj it 's a concept visited by filmmaker xxmaj cameron xxmaj crowe in his</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>xxbos xxup n.b . : xxmaj spoilers within . xxmaj assigning an artistic director to an operatic production naturally and inevitably means you are going to get a piece of that director 's mind . xxmaj but directing a xxmaj wagner opera is an especially tricky task , as he was perhaps the most explicit opera composer in terms of what things should look like and how they should unfold . hans - jurgen xxmaj syberberg loads this filming of \" parsifal , \" xxmaj wagner 's final masterpiece , with enough extraneous ideas to cause it to nearly burst at the seams . xxmaj you get more than a piece of the director : you get the whole xxunk hog and then some . xxmaj syberberg is to be admired for his penchant for tearing back the covers on the uglier aspects of xxmaj german history . xxmaj but</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>xxbos xxmaj the vigilante has long held a fascination for audiences , inasmuch as it evokes a sense of swift , sure justice ; good triumphs over evil and the bad guy gets his deserts . xxmaj it is , in fact , one of the things that has made the character of xxmaj dirty xxmaj harry xxmaj callahan ( as played by xxmaj clint xxmaj eastwood ) so popular . xxmaj he carries a badge and works within the law , but at heart , xxmaj harry is a vigilante , meting out justice ` his ' way , which often puts him in conflict with his own superiors , as well as the criminals he 's pursuing . xxmaj but it 's what draws the audience ; anyone who 's ever been bogged down in bureaucratic nonsense of one kind or another , delights in seeing someone cut</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2 id=\"TextBlock\" class=\"doc_header\"><code>class</code> <code>TextBlock</code><a href=\"https://github.com/fastai/fastai/tree/master/fastai/text/data.py#L219\" class=\"source_link\" style=\"float:right\">[source]</a></h2><blockquote><p><code>TextBlock</code>(<strong><code>tok_tfm</code></strong>, <strong><code>vocab</code></strong>=<em><code>None</code></em>, <strong><code>is_lm</code></strong>=<em><code>False</code></em>, <strong><code>seq_len</code></strong>=<em><code>72</code></em>, <strong><code>backwards</code></strong>=<em><code>False</code></em>, <strong><code>min_freq</code></strong>=<em><code>3</code></em>, <strong><code>max_vocab</code></strong>=<em><code>60000</code></em>, <strong><code>special_toks</code></strong>=<em><code>None</code></em>) :: <code>TransformBlock</code></p>\n",
       "</blockquote>\n",
       "<p>A <code>TransformBlock</code> for texts</p>\n",
       "<p><a href=\"https://docs.fast.ai/text.data#TextBlock\" target=\"_blank\" rel=\"noreferrer noopener\">Show in docs</a></p>\n",
       "<style>\n",
       "    table { border-collapse: collapse; border:thin solid #dddddd; margin: 25px 0px; ; }\n",
       "    table tr:first-child { background-color: #FFF}\n",
       "    table thead th { background-color: #eee; color: #000; text-align: center;}\n",
       "    tr, th, td { border: 1px solid #ccc; border-width: 1px 0 0 1px; border-collapse: collapse;\n",
       "    padding: 5px; }\n",
       "    tr:nth-child(even) {background: #eee;}</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc(TextBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mNumericalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mspecial_toks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m        \n",
       "\u001b[0;32mclass\u001b[0m \u001b[0mNumericalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"Reversible transform of tokenized texts to numericalized ids\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecial_toks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mstore_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vocab,min_freq,max_vocab,special_toks'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mo2i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvocab\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0msetups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mdsets\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdsets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcounter\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'counter'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdsets\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_toks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'special_toks'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_toks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdsets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_toks\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecial_toks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_toks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mo2i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'xxfake'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mencodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mTensorText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mo2i\u001b[0m  \u001b[0;34m[\u001b[0m\u001b[0mo_\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mdecodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo_\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m           ~/mambaforge/lib/python3.9/site-packages/fastai/text/data.py\n",
       "\u001b[0;31mType:\u001b[0m           _TfmMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Numericalize??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is hasattr? in python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Car:\n",
    "    def __init__(self, model_name: str, brand: str, year: int):\n",
    "        self.model = model_name\n",
    "        self.brand = brand\n",
    "        self.year = year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Car(model_name=\"Verna\", brand=\"Hyndai\", year=2009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Verna'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(c,\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(c, \"price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(c, \"year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = get_text_files(path, folders = ['train', 'test'])\n",
    "txts = L(o.open().read() for o in files[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2000) [\"What could have been an excellent hostage movie was totally ruined by what apparently looks like a bored director ... there were so many directions that the movie could have taken ... a vampire slash-fest was not one of these!!! The last 45 mins. or so results in the movie being an absolutely ridiculous waste of time. ...and sex machine?? ... you gotta be kidding me! The acting talents of the likes of Juliette Lewis and Harvey Keitel (not to mention George Clooney) are completely wasted in this nonsensical movie. <br /><br />The director... Robert Rodriguez, known for his other gory flicks including el mariachi, desperado, once upon a time in Mexico, and the very recent sin city ... really holds your attention with the well executed first half ... which leads you to believe that you are in for an entertaining time ... but then apparently for no reason, and without any provocation, the madness starts ... there's even feeble attempts at parody and comedy ... truly exasperating!!\",'One of the problems with popular culture, especially when discussing the popular culture of the 1970s, is that mass media - especially television - is usually about four years behind \\'underground\\' media, primarily music. Many people think the \\'Woodstock Generation\" remained important throughout the 1970s; actually, it was all over at Altamont in 1970. By 1972, \\'underground\\' rock or the \\'counterculture\\' had moved east to England and Led Zepplin, Black sabbath, and David Bowie, early metal-heads and the so-called \\'glam-rockers,\\' who were all \\'peace and love\\' - not. Neither, in a darkly different vein, was Charles Manson\\'s \\'family.\\' <br /><br />This obvious pilot for a television show (that, thankfully, was never picked up by the networks) is attempting to come to terms with a culture that was already as withered as yesterday\\'s flowers. The script must have been lying around a few years - by the time it was produced, writer Carlino had already achieved recognition for tough Mafia revenge tales. And the cultural references are all to \"Easy Rider\" and Woodstock (1969). The music referenced on the soundtrack is actually earlier, 1966/67 - at Woodstock Hendrix, Canned Heat, and Sly and the Family Stone had blasted this kind of folk-pop into oblivion.<br /><br />The movie is about a middle-class family that goes on the road in order to meet hippies. Wow, man, farout, outasight, it\\'s a groovy mind-blowing happening of a bag. However, politics count for nothing - Vietnam? some place in Asia, right? <br /><br />This average (meaning stale and vacuous) TV movie is only redeemed by Jeff Bridges\\' surprisingly mature performance as the young college drop-out who convinces his parents and grandma to \\'discover\\' (hippie) America. All the rest of the performances are standard TV fair by standard TV actors of the time. The director avails himself of some nice location cinematography, but otherwise the film is a poor way to spend 90 minutes.<br /><br />I knew it was all over when Sal Mineo remarks of a young runaway (who tells the other characters they are not really there): \"She\\'s a latent existentialist.\" Wow, far out, groovy. <br /><br />A couple extra points for being \\'so bad it\\'s funny,\\' but if you don\\'t care about the \\'70\\'s TV version of the \\'60\\'s, stay away.','This is not a movie. This is a collection of random shots taken in a fascinating part of the world, dubbed over with some random text. The footage is not that great and the text is not that great either. The end product is excruciatingly dull.<br /><br />On the DVD, turning the commentary on can provide some entertainment value, as the director makes a rather deranged argument that this is a sci-fi movie. It\\'s also fascinating to read about the extraordinary risks and hardship that the crew endured to collect this footage. Too bad it\\'s rubbish. But I think \"The Making of Fata Morgana\" would be a fascinating film, sort-of like \\'Ed Wood\" was.',\"It's 2005, my friends...a time of amazing special effects and an age of technology. So, why can't we see a movie that's a little more thought out than this cheesy low-budget film. I've seen a lot of low-budget movies that rock my socks off, but this one...it's almost as if it's trying to be horrible. Just...don't...watch it. I can look past lack of special effects and computer generated scenes if the acting itself was at least good. I feel like a small child produced this entire movie. There's not even an original plot line. Vampire Assassins, in itself is one big plot hole with an attempt to mock itself. Can someone tell me if, perhaps, this was designed as a comedy movie and I just didn't know it? It makes me wonder, what does the sequel have in store for us who so loved the first installment?\",'Poorly acted and poorly directed, \"Congo\" unsuccessfully tries to recreate the feeling of \"Jurassic Park\". But the truth is, the book wasn\\'t all that great either. Still, the movie\\'s first problem is that Tim Curry\\'s character was added; the second problem is that the talking arm was added; the main problem, though, is that the cast members don\\'t create realistic characters. I guarantee that this movie will not make you think that there are killer gorillas anywhere on earth. Also starring Laura Linney (happy birthday, Laura!), Dylan Walsh, Ernie Hudson, Grant Heslov, Joe Don Baker, James Karen and Bruce Campbell; I\\'m guessing that they don\\'t wish to emphasize this movie in their resumes.',\"I wish I had read the comments on IMDb before I saw this movie. The first 1 hour was OK, though it did make me wonder why everything was centered at Chicago and why no one reported any weather anomaly from outside US. Isolated acts of nature (of this magnitude) are unthinkable. But beyond the first 60 minutes, the movie just drags on like a never-ending story. The screenplay is horrible. As for the actors, very poor choice. Only the people hired to run in panic stick to their roles. But I do have to agree that this movie has got some good 'special effects'. If you rented it on a DVD and would want to watch the movie, despite the reviews, then play it on maximum speed your player would allow!\",'I probably have to blame myself\\x85but I sure as hell expected more from a movie that goes by the title \"Black Dragons\" and revolves on secret WWII conspiracies, Nazi plastic surgeons and revenge. This film is a dull failure with an incomprehensible structure. The actual plot (which basically is rather ingenious and intriguing) only becomes clear during an explication near the end, but the problem is that you stop caring a long time before. We see how horror icon Bela Lugosi infiltrates in a society of prominent American politicians and kills them one by one. The story is timed right before WWII and \\x96 especially after witnessing the ending \\x96 it surely is a premise with lots of potential, so it\\'s quite a shame it isn\\'t elaborated more proper. There is however one great dialogue that I can\\'t resist sharing! Man towards woman: \"Do you want to marry me?\" \"Why?\" \"So I can beat you up\\x85it\\'s the only way you\\'ll leave this place!\" It\\'s the only highlight in an overall very boring movie. Bela Lugosi is lovely \\x96 as usual \\x96 but his spooky performance alone is hardly worth purchasing this film. If you\\'re interested in seeing other ghoulish performances of his (in movies with decent screenplays), check out \"Invisible Ghost\", \"The Corpse Vanishes\", \"White Zombie\" and of course the 1931 Dracula version.','Worst. Movie. Ever. I can\\'t believe they had to hire Jeremy Irons to give this piece of crap some credibility - and still failed. Did they think that if they stuck to the plot of the book that their target audience wouldn\\'t be able to figure it out on their own? (probably). \"Hey, let\\'s make lots of things explode and give Mina big boobs, and have her speak in an adorably fake broken English. That\\'ll make the morons watch.\" \"But sir, that\\'s not how the book went at all, I think we\\'re mot being faithful to Mr. Wells\\' message.\" \"F*ck it, we\\'re going to the box office here, never mind some dead author\\'s ideas on human nature. Also, let\\'s add in Orlando Jones with some classic \\'Black attitude\\' as a supporting character, and never mind the interesting conclusion to the book - Guy Pierce has to get some p*ssy at the end.\"','I went to the cinema slightly apprehensive, I came out seething with anger at the garbage (passing for a film)I had witnessed. The actors, particularly Travolta, should be ashamed of themselves for their participation in this. Clearly the only thing in their minds was the pay cheque, never mind the debasement of their talents and us . Travolta needs to go back to doing some more \"Look who\\'s Talking\" movies as he has sunk back to the level of his pre-Tarantino work. It comes to something when the L W Talking sequels are better than this one. Travolta is no longer the King of Cool but the King of Corn. Michael Caine himself admitted to doing bad movies for the pay cheque, Trvolta should follow suit if he has any self respect !','Unfortunately, I went to this movie for entertainment purposes based on the limited information I had seen on Fandango. Since I am a sci-fi buff the notion of a movie about UFOs interested me.<br /><br />Instead, this movie quickly revealed itself as an evangelical Christian propaganda flick. Appropriate for an audience of like-minded individuals but very un-Christian like to exploit the movie mall scene and preach to an unsuspecting audience, especially considering the costs of tickets and concessions. Shame on you! At least the Da Vinci Code did not hold back its wild-eyed craziness.<br /><br />So, this B-grade movie (and I am being kind) production will be appreciated in those churches with similar beliefs, probably shown to Wednesday and Sunday evening youth groups. But if you are a mainline Christian or non-Christian you will not be comfortable.'...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrules\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcounter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m        \n",
       "\u001b[0;32mclass\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"Provides a consistent `Transform` interface to tokenizers operating on `DataFrame`s and folders\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minput_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mstore_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tok,counter,lengths,mode,sep'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_proc_rules\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrules\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mdelegates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mfrom_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mtok\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrules\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'df'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_setup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'tok'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_cols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_cols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mdelegates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mfrom_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mtok\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrules\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfn_counter_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                  \u001b[0mlengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfn_lengths_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrules\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'folder'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0msetups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'df'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdsets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrules\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcounter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mdsets\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mencodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'folder'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelative_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'UTF-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenize1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mencodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenize1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_tokenize1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mget_lengths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlengths\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'df'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'text_lengths'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_length'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'folder'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelative_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mdecodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mTitledStr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m           ~/mambaforge/lib/python3.9/site-packages/fastai/text/core.py\n",
       "\u001b[0;31mType:\u001b[0m           _TfmMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Tokenizer??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#207) ['xxbos','xxmaj','what','could','have','been','an','excellent','hostage','movie'...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok = Tokenizer.from_folder(path)\n",
    "tok.setup(txts)\n",
    "toks = txts.map(tok)\n",
    "toks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2000) [['xxbos', 'xxmaj', 'what', 'could', 'have', 'been', 'an', 'excellent', 'hostage', 'movie', 'was', 'totally', 'ruined', 'by', 'what', 'apparently', 'looks', 'like', 'a', 'bored', 'director', '…', 'there', 'were', 'so', 'many', 'directions', 'that', 'the', 'movie', 'could', 'have', 'taken', '…', 'a', 'vampire', 'slash', '-', 'fest', 'was', 'not', 'one', 'of', 'these', 'xxrep', '3', '!', 'xxmaj', 'the', 'last', '45', 'mins', '.', 'or', 'so', 'results', 'in', 'the', 'movie', 'being', 'an', 'absolutely', 'ridiculous', 'waste', 'of', 'time', '.', '…', 'and', 'sex', 'machine', '?', '?', '…', 'you', 'got', 'ta', 'be', 'kidding', 'me', '!', 'xxmaj', 'the', 'acting', 'talents', 'of', 'the', 'likes', 'of', 'xxmaj', 'juliette', 'xxmaj', 'lewis', 'and', 'xxmaj', 'harvey', 'xxmaj', 'keitel', '(', 'not', 'to', 'mention', 'xxmaj', 'george', 'xxmaj', 'clooney', ')', 'are', 'completely', 'wasted', 'in', 'this', 'nonsensical', 'movie', '.', '\\n\\n', 'xxmaj', 'the', 'director', '…', 'xxmaj', 'robert', 'xxmaj', 'rodriguez', ',', 'known', 'for', 'his', 'other', 'gory', 'flicks', 'including', 'el', 'mariachi', ',', 'desperado', ',', 'once', 'upon', 'a', 'time', 'in', 'xxmaj', 'mexico', ',', 'and', 'the', 'very', 'recent', 'sin', 'city', '…', 'really', 'holds', 'your', 'attention', 'with', 'the', 'well', 'executed', 'first', 'half', '…', 'which', 'leads', 'you', 'to', 'believe', 'that', 'you', 'are', 'in', 'for', 'an', 'entertaining', 'time', '…', 'but', 'then', 'apparently', 'for', 'no', 'reason', ',', 'and', 'without', 'any', 'provocation', ',', 'the', 'madness', 'starts', '…', 'there', \"'s\", 'even', 'feeble', 'attempts', 'at', 'parody', 'and', 'comedy', '…', 'truly', 'exasperating', '!', '!'],['xxbos', 'xxmaj', 'one', 'of', 'the', 'problems', 'with', 'popular', 'culture', ',', 'especially', 'when', 'discussing', 'the', 'popular', 'culture', 'of', 'the', '1970s', ',', 'is', 'that', 'mass', 'media', '-', 'especially', 'television', '-', 'is', 'usually', 'about', 'four', 'years', 'behind', \"'\", 'underground', \"'\", 'media', ',', 'primarily', 'music', '.', 'xxmaj', 'many', 'people', 'think', 'the', \"'\", 'woodstock', 'xxmaj', 'generation', '\"', 'remained', 'important', 'throughout', 'the', '1970s', ';', 'actually', ',', 'it', 'was', 'all', 'over', 'at', 'xxmaj', 'altamont', 'in', '1970', '.', 'xxmaj', 'by', '1972', ',', \"'\", 'underground', \"'\", 'rock', 'or', 'the', \"'\", 'counterculture', \"'\", 'had', 'moved', 'east', 'to', 'xxmaj', 'england', 'and', 'xxmaj', 'led', 'xxmaj', 'zepplin', ',', 'xxmaj', 'black', 'sabbath', ',', 'and', 'xxmaj', 'david', 'xxmaj', 'bowie', ',', 'early', 'metal', '-', 'heads', 'and', 'the', 'so', '-', 'called', \"'\", 'glam', '-', 'rockers', ',', \"'\", 'who', 'were', 'all', \"'\", 'peace', 'and', 'love', \"'\", '-', 'not', '.', 'xxmaj', 'neither', ',', 'in', 'a', 'darkly', 'different', 'vein', ',', 'was', 'xxmaj', 'charles', 'xxmaj', 'manson', \"'s\", \"'\", 'family', '.', \"'\", '\\n\\n', 'xxmaj', 'this', 'obvious', 'pilot', 'for', 'a', 'television', 'show', '(', 'that', ',', 'thankfully', ',', 'was', 'never', 'picked', 'up', 'by', 'the', 'networks', ')', 'is', 'attempting', 'to', 'come', 'to', 'terms', 'with', 'a', 'culture', 'that', 'was', 'already', 'as', 'withered', 'as', 'yesterday', \"'s\", 'flowers', '.', 'xxmaj', 'the', 'script', 'must', 'have', 'been', 'lying', 'around', 'a', 'few', 'years', '-', 'by', 'the', 'time', 'it', 'was', 'produced', ',', 'writer', 'xxmaj', 'carlino', 'had', 'already', 'achieved', 'recognition', 'for', 'tough', 'xxmaj', 'mafia', 'revenge', 'tales', '.', 'xxmaj', 'and', 'the', 'cultural', 'references', 'are', 'all', 'to', '\"', 'easy', 'xxmaj', 'rider', '\"', 'and', 'xxmaj', 'woodstock', '(', '1969', ')', '.', 'xxmaj', 'the', 'music', 'referenced', 'on', 'the', 'soundtrack', 'is', 'actually', 'earlier', ',', '1966', '/', '67', '-', 'at', 'xxmaj', 'woodstock', 'xxmaj', 'hendrix', ',', 'xxmaj', 'canned', 'xxmaj', 'heat', ',', 'and', 'xxmaj', 'sly', 'and', 'the', 'xxmaj', 'family', 'xxmaj', 'stone', 'had', 'blasted', 'this', 'kind', 'of', 'folk', '-', 'pop', 'into', 'oblivion', '.', '\\n\\n', 'xxmaj', 'the', 'movie', 'is', 'about', 'a', 'middle', '-', 'class', 'family', 'that', 'goes', 'on', 'the', 'road', 'in', 'order', 'to', 'meet', 'hippies', '.', 'xxmaj', 'wow', ',', 'man', ',', 'farout', ',', 'outasight', ',', 'it', \"'s\", 'a', 'groovy', 'mind', '-', 'blowing', 'happening', 'of', 'a', 'bag', '.', 'xxmaj', 'however', ',', 'politics', 'count', 'for', 'nothing', '-', 'xxmaj', 'vietnam', '?', 'some', 'place', 'in', 'xxmaj', 'asia', ',', 'right', '?', '\\n\\n', 'xxmaj', 'this', 'average', '(', 'meaning', 'stale', 'and', 'vacuous', ')', 'xxup', 'tv', 'movie', 'is', 'only', 'redeemed', 'by', 'xxmaj', 'jeff', 'xxmaj', 'bridges', \"'\", 'surprisingly', 'mature', 'performance', 'as', 'the', 'young', 'college', 'drop', '-', 'out', 'who', 'convinces', 'his', 'parents', 'and', 'grandma', 'to', \"'\", 'discover', \"'\", '(', 'hippie', ')', 'xxmaj', 'america', '.', 'xxmaj', 'all', 'the', 'rest', 'of', 'the', 'performances', 'are', 'standard', 'xxup', 'tv', 'fair', 'by', 'standard', 'xxup', 'tv', 'actors', 'of', 'the', 'time', '.', 'xxmaj', 'the', 'director', 'avails', 'himself', 'of', 'some', 'nice', 'location', 'cinematography', ',', 'but', 'otherwise', 'the', 'film', 'is', 'a', 'poor', 'way', 'to', 'spend', '90', 'minutes', '.', '\\n\\n', 'i', 'knew', 'it', 'was', 'all', 'over', 'when', 'xxmaj', 'sal', 'xxmaj', 'mineo', 'remarks', 'of', 'a', 'young', 'runaway', '(', 'who', 'tells', 'the', 'other', 'characters', 'they', 'are', 'not', 'really', 'there', '):', '\"', 'she', \"'s\", 'a', 'latent', 'existentialist', '.', '\"', 'xxmaj', 'wow', ',', 'far', 'out', ',', 'groovy', '.', '\\n\\n', 'a', 'couple', 'extra', 'points', 'for', 'being', \"'\", 'so', 'bad', 'it', \"'s\", 'funny', ',', \"'\", 'but', 'if', 'you', 'do', \"n't\", 'care', 'about', 'the', \"'\", '70', \"'s\", 'xxup', 'tv', 'version', 'of', 'the', \"'\", '60', \"'s\", ',', 'stay', 'away', '.'],['xxbos', 'xxmaj', 'this', 'is', 'not', 'a', 'movie', '.', 'xxmaj', 'this', 'is', 'a', 'collection', 'of', 'random', 'shots', 'taken', 'in', 'a', 'fascinating', 'part', 'of', 'the', 'world', ',', 'dubbed', 'over', 'with', 'some', 'random', 'text', '.', 'xxmaj', 'the', 'footage', 'is', 'not', 'that', 'great', 'and', 'the', 'text', 'is', 'not', 'that', 'great', 'either', '.', 'xxmaj', 'the', 'end', 'product', 'is', 'excruciatingly', 'dull', '.', '\\n\\n', 'xxmaj', 'on', 'the', 'xxup', 'dvd', ',', 'turning', 'the', 'commentary', 'on', 'can', 'provide', 'some', 'entertainment', 'value', ',', 'as', 'the', 'director', 'makes', 'a', 'rather', 'deranged', 'argument', 'that', 'this', 'is', 'a', 'sci', '-', 'fi', 'movie', '.', 'xxmaj', 'it', \"'s\", 'also', 'fascinating', 'to', 'read', 'about', 'the', 'extraordinary', 'risks', 'and', 'hardship', 'that', 'the', 'crew', 'endured', 'to', 'collect', 'this', 'footage', '.', 'xxmaj', 'too', 'bad', 'it', \"'s\", 'rubbish', '.', 'xxmaj', 'but', 'i', 'think', '\"', 'the', 'xxmaj', 'making', 'of', 'xxmaj', 'fata', 'xxmaj', 'morgana', '\"', 'would', 'be', 'a', 'fascinating', 'film', ',', 'sort', '-', 'of', 'like', \"'\", 'ed', 'xxmaj', 'wood', '\"', 'was', '.'],['xxbos', 'xxmaj', 'it', \"'s\", '2005', ',', 'my', 'friends', '…', 'a', 'time', 'of', 'amazing', 'special', 'effects', 'and', 'an', 'age', 'of', 'technology', '.', 'xxmaj', 'so', ',', 'why', 'ca', \"n't\", 'we', 'see', 'a', 'movie', 'that', \"'s\", 'a', 'little', 'more', 'thought', 'out', 'than', 'this', 'cheesy', 'low', '-', 'budget', 'film', '.', 'xxmaj', 'i', \"'ve\", 'seen', 'a', 'lot', 'of', 'low', '-', 'budget', 'movies', 'that', 'rock', 'my', 'socks', 'off', ',', 'but', 'this', 'one', '…', 'it', \"'s\", 'almost', 'as', 'if', 'it', \"'s\", 'trying', 'to', 'be', 'horrible', '.', 'xxmaj', 'just', '…', 'do', \"n't\", '…', 'watch', 'it', '.', 'i', 'can', 'look', 'past', 'lack', 'of', 'special', 'effects', 'and', 'computer', 'generated', 'scenes', 'if', 'the', 'acting', 'itself', 'was', 'at', 'least', 'good', '.', 'i', 'feel', 'like', 'a', 'small', 'child', 'produced', 'this', 'entire', 'movie', '.', 'xxmaj', 'there', \"'s\", 'not', 'even', 'an', 'original', 'plot', 'line', '.', 'xxmaj', 'vampire', 'xxmaj', 'assassins', ',', 'in', 'itself', 'is', 'one', 'big', 'plot', 'hole', 'with', 'an', 'attempt', 'to', 'mock', 'itself', '.', 'xxmaj', 'can', 'someone', 'tell', 'me', 'if', ',', 'perhaps', ',', 'this', 'was', 'designed', 'as', 'a', 'comedy', 'movie', 'and', 'i', 'just', 'did', \"n't\", 'know', 'it', '?', 'xxmaj', 'it', 'makes', 'me', 'wonder', ',', 'what', 'does', 'the', 'sequel', 'have', 'in', 'store', 'for', 'us', 'who', 'so', 'loved', 'the', 'first', 'installment', '?'],['xxbos', 'xxmaj', 'poorly', 'acted', 'and', 'poorly', 'directed', ',', '\"', 'congo', '\"', 'unsuccessfully', 'tries', 'to', 'recreate', 'the', 'feeling', 'of', '\"', 'jurassic', 'xxmaj', 'park', '\"', '.', 'xxmaj', 'but', 'the', 'truth', 'is', ',', 'the', 'book', 'was', \"n't\", 'all', 'that', 'great', 'either', '.', 'xxmaj', 'still', ',', 'the', 'movie', \"'s\", 'first', 'problem', 'is', 'that', 'xxmaj', 'tim', 'xxmaj', 'curry', \"'s\", 'character', 'was', 'added', ';', 'the', 'second', 'problem', 'is', 'that', 'the', 'talking', 'arm', 'was', 'added', ';', 'the', 'main', 'problem', ',', 'though', ',', 'is', 'that', 'the', 'cast', 'members', 'do', \"n't\", 'create', 'realistic', 'characters', '.', 'i', 'guarantee', 'that', 'this', 'movie', 'will', 'not', 'make', 'you', 'think', 'that', 'there', 'are', 'killer', 'gorillas', 'anywhere', 'on', 'earth', '.', 'xxmaj', 'also', 'starring', 'xxmaj', 'laura', 'xxmaj', 'linney', '(', 'happy', 'birthday', ',', 'xxmaj', 'laura', '!', ')', ',', 'xxmaj', 'dylan', 'xxmaj', 'walsh', ',', 'xxmaj', 'ernie', 'xxmaj', 'hudson', ',', 'xxmaj', 'grant', 'xxmaj', 'heslov', ',', 'xxmaj', 'joe', 'xxmaj', 'don', 'xxmaj', 'baker', ',', 'xxmaj', 'james', 'xxmaj', 'karen', 'and', 'xxmaj', 'bruce', 'xxmaj', 'campbell', ';', 'xxmaj', 'i', \"'m\", 'guessing', 'that', 'they', 'do', \"n't\", 'wish', 'to', 'emphasize', 'this', 'movie', 'in', 'their', 'resumes', '.'],['xxbos', 'i', 'wish', 'i', 'had', 'read', 'the', 'comments', 'on', 'imdb', 'before', 'i', 'saw', 'this', 'movie', '.', 'xxmaj', 'the', 'first', '1', 'hour', 'was', 'xxup', 'ok', ',', 'though', 'it', 'did', 'make', 'me', 'wonder', 'why', 'everything', 'was', 'centered', 'at', 'xxmaj', 'chicago', 'and', 'why', 'no', 'one', 'reported', 'any', 'weather', 'anomaly', 'from', 'outside', 'xxup', 'us', '.', 'xxmaj', 'isolated', 'acts', 'of', 'nature', '(', 'of', 'this', 'magnitude', ')', 'are', 'unthinkable', '.', 'xxmaj', 'but', 'beyond', 'the', 'first', '60', 'minutes', ',', 'the', 'movie', 'just', 'drags', 'on', 'like', 'a', 'never', '-', 'ending', 'story', '.', 'xxmaj', 'the', 'screenplay', 'is', 'horrible', '.', 'xxmaj', 'as', 'for', 'the', 'actors', ',', 'very', 'poor', 'choice', '.', 'xxmaj', 'only', 'the', 'people', 'hired', 'to', 'run', 'in', 'panic', 'stick', 'to', 'their', 'roles', '.', 'xxmaj', 'but', 'i', 'do', 'have', 'to', 'agree', 'that', 'this', 'movie', 'has', 'got', 'some', 'good', \"'\", 'special', 'effects', \"'\", '.', 'xxmaj', 'if', 'you', 'rented', 'it', 'on', 'a', 'xxup', 'dvd', 'and', 'would', 'want', 'to', 'watch', 'the', 'movie', ',', 'despite', 'the', 'reviews', ',', 'then', 'play', 'it', 'on', 'maximum', 'speed', 'your', 'player', 'would', 'allow', '!'],['xxbos', 'i', 'probably', 'have', 'to', 'blame', 'myself', '\\x85', 'but', 'i', 'sure', 'as', 'hell', 'expected', 'more', 'from', 'a', 'movie', 'that', 'goes', 'by', 'the', 'title', '\"', 'black', 'xxmaj', 'dragons', '\"', 'and', 'revolves', 'on', 'secret', 'xxup', 'wwii', 'conspiracies', ',', 'xxmaj', 'nazi', 'plastic', 'surgeons', 'and', 'revenge', '.', 'xxmaj', 'this', 'film', 'is', 'a', 'dull', 'failure', 'with', 'an', 'incomprehensible', 'structure', '.', 'xxmaj', 'the', 'actual', 'plot', '(', 'which', 'basically', 'is', 'rather', 'ingenious', 'and', 'intriguing', ')', 'only', 'becomes', 'clear', 'during', 'an', 'explication', 'near', 'the', 'end', ',', 'but', 'the', 'problem', 'is', 'that', 'you', 'stop', 'caring', 'a', 'long', 'time', 'before', '.', 'xxmaj', 'we', 'see', 'how', 'horror', 'icon', 'xxmaj', 'bela', 'xxmaj', 'lugosi', 'infiltrates', 'in', 'a', 'society', 'of', 'prominent', 'xxmaj', 'american', 'politicians', 'and', 'kills', 'them', 'one', 'by', 'one', '.', 'xxmaj', 'the', 'story', 'is', 'timed', 'right', 'before', 'xxup', 'wwii', 'and', '\\x96', 'especially', 'after', 'witnessing', 'the', 'ending', '\\x96', 'it', 'surely', 'is', 'a', 'premise', 'with', 'lots', 'of', 'potential', ',', 'so', 'it', \"'s\", 'quite', 'a', 'shame', 'it', 'is', \"n't\", 'elaborated', 'more', 'proper', '.', 'xxmaj', 'there', 'is', 'however', 'one', 'great', 'dialogue', 'that', 'i', 'ca', \"n't\", 'resist', 'sharing', '!', 'xxmaj', 'man', 'towards', 'woman', ':', '\"', 'do', 'you', 'want', 'to', 'marry', 'me', '?', '\"', '\"', 'why', '?', '\"', '\"', 'so', 'i', 'can', 'beat', 'you', 'up', '\\x85', 'it', \"'s\", 'the', 'only', 'way', 'you', \"'ll\", 'leave', 'this', 'place', '!', '\"', 'xxmaj', 'it', \"'s\", 'the', 'only', 'highlight', 'in', 'an', 'overall', 'very', 'boring', 'movie', '.', 'xxmaj', 'bela', 'xxmaj', 'lugosi', 'is', 'lovely', '\\x96', 'as', 'usual', '\\x96', 'but', 'his', 'spooky', 'performance', 'alone', 'is', 'hardly', 'worth', 'purchasing', 'this', 'film', '.', 'xxmaj', 'if', 'you', \"'re\", 'interested', 'in', 'seeing', 'other', 'ghoulish', 'performances', 'of', 'his', '(', 'in', 'movies', 'with', 'decent', 'screenplays', ')', ',', 'check', 'out', '\"', 'invisible', 'xxmaj', 'ghost', '\"', ',', '\"', 'the', 'xxmaj', 'corpse', 'xxmaj', 'vanishes', '\"', ',', '\"', 'white', 'xxmaj', 'zombie', '\"', 'and', 'of', 'course', 'the', '1931', 'xxmaj', 'dracula', 'version', '.'],['xxbos', 'xxmaj', 'worst', '.', 'xxmaj', 'movie', '.', 'xxmaj', 'ever', '.', 'i', 'ca', \"n't\", 'believe', 'they', 'had', 'to', 'hire', 'xxmaj', 'jeremy', 'xxmaj', 'irons', 'to', 'give', 'this', 'piece', 'of', 'crap', 'some', 'credibility', '-', 'and', 'still', 'failed', '.', 'xxmaj', 'did', 'they', 'think', 'that', 'if', 'they', 'stuck', 'to', 'the', 'plot', 'of', 'the', 'book', 'that', 'their', 'target', 'audience', 'would', \"n't\", 'be', 'able', 'to', 'figure', 'it', 'out', 'on', 'their', 'own', '?', '(', 'probably', ')', '.', '\"', 'hey', ',', 'let', \"'s\", 'make', 'lots', 'of', 'things', 'explode', 'and', 'give', 'xxmaj', 'mina', 'big', 'boobs', ',', 'and', 'have', 'her', 'speak', 'in', 'an', 'adorably', 'fake', 'broken', 'xxmaj', 'english', '.', 'xxmaj', 'that', \"'ll\", 'make', 'the', 'morons', 'watch', '.', '\"', '\"', 'but', 'sir', ',', 'that', \"'s\", 'not', 'how', 'the', 'book', 'went', 'at', 'all', ',', 'i', 'think', 'we', \"'re\", 'mot', 'being', 'faithful', 'to', 'xxmaj', 'mr', '.', 'xxmaj', 'wells', \"'\", 'message', '.', '\"', '\"', 'f*ck', 'it', ',', 'we', \"'re\", 'going', 'to', 'the', 'box', 'office', 'here', ',', 'never', 'mind', 'some', 'dead', 'author', \"'s\", 'ideas', 'on', 'human', 'nature', '.', 'xxmaj', 'also', ',', 'let', \"'s\", 'add', 'in', 'xxmaj', 'orlando', 'xxmaj', 'jones', 'with', 'some', 'classic', \"'\", 'black', 'attitude', \"'\", 'as', 'a', 'supporting', 'character', ',', 'and', 'never', 'mind', 'the', 'interesting', 'conclusion', 'to', 'the', 'book', '-', 'xxmaj', 'guy', 'xxmaj', 'pierce', 'has', 'to', 'get', 'some', 'p*ssy', 'at', 'the', 'end', '.', '\"'],['xxbos', 'i', 'went', 'to', 'the', 'cinema', 'slightly', 'apprehensive', ',', 'i', 'came', 'out', 'seething', 'with', 'anger', 'at', 'the', 'garbage', '(', 'passing', 'for', 'a', 'film)i', 'had', 'witnessed', '.', 'xxmaj', 'the', 'actors', ',', 'particularly', 'xxmaj', 'travolta', ',', 'should', 'be', 'ashamed', 'of', 'themselves', 'for', 'their', 'participation', 'in', 'this', '.', 'xxmaj', 'clearly', 'the', 'only', 'thing', 'in', 'their', 'minds', 'was', 'the', 'pay', 'cheque', ',', 'never', 'mind', 'the', 'debasement', 'of', 'their', 'talents', 'and', 'us', '.', 'xxmaj', 'travolta', 'needs', 'to', 'go', 'back', 'to', 'doing', 'some', 'more', '\"', 'look', 'who', \"'s\", 'xxmaj', 'talking', '\"', 'movies', 'as', 'he', 'has', 'sunk', 'back', 'to', 'the', 'level', 'of', 'his', 'pre', '-', 'tarantino', 'work', '.', 'xxmaj', 'it', 'comes', 'to', 'something', 'when', 'the', 'l', 'w', 'xxmaj', 'talking', 'sequels', 'are', 'better', 'than', 'this', 'one', '.', 'xxmaj', 'travolta', 'is', 'no', 'longer', 'the', 'xxmaj', 'king', 'of', 'xxmaj', 'cool', 'but', 'the', 'xxmaj', 'king', 'of', 'xxmaj', 'corn', '.', 'xxmaj', 'michael', 'xxmaj', 'caine', 'himself', 'admitted', 'to', 'doing', 'bad', 'movies', 'for', 'the', 'pay', 'cheque', ',', 'xxmaj', 'trvolta', 'should', 'follow', 'suit', 'if', 'he', 'has', 'any', 'self', 'respect', '!'],['xxbos', 'xxmaj', 'unfortunately', ',', 'i', 'went', 'to', 'this', 'movie', 'for', 'entertainment', 'purposes', 'based', 'on', 'the', 'limited', 'information', 'i', 'had', 'seen', 'on', 'xxmaj', 'fandango', '.', 'xxmaj', 'since', 'i', 'am', 'a', 'sci', '-', 'fi', 'buff', 'the', 'notion', 'of', 'a', 'movie', 'about', 'ufos', 'interested', 'me', '.', '\\n\\n', 'xxmaj', 'instead', ',', 'this', 'movie', 'quickly', 'revealed', 'itself', 'as', 'an', 'evangelical', 'xxmaj', 'christian', 'propaganda', 'flick', '.', 'xxmaj', 'appropriate', 'for', 'an', 'audience', 'of', 'like', '-', 'minded', 'individuals', 'but', 'very', 'un', '-', 'christian', 'like', 'to', 'exploit', 'the', 'movie', 'mall', 'scene', 'and', 'preach', 'to', 'an', 'unsuspecting', 'audience', ',', 'especially', 'considering', 'the', 'costs', 'of', 'tickets', 'and', 'concessions', '.', 'xxmaj', 'shame', 'on', 'you', '!', 'xxmaj', 'at', 'least', 'the', 'xxmaj', 'da', 'xxmaj', 'vinci', 'xxmaj', 'code', 'did', 'not', 'hold', 'back', 'its', 'wild', '-', 'eyed', 'craziness', '.', '\\n\\n', 'xxmaj', 'so', ',', 'this', 'xxmaj', 'b', '-', 'grade', 'movie', '(', 'and', 'i', 'am', 'being', 'kind', ')', 'production', 'will', 'be', 'appreciated', 'in', 'those', 'churches', 'with', 'similar', 'beliefs', ',', 'probably', 'shown', 'to', 'xxmaj', 'wednesday', 'and', 'xxmaj', 'sunday', 'evening', 'youth', 'groups', '.', 'xxmaj', 'but', 'if', 'you', 'are', 'a', 'mainline', 'xxmaj', 'christian', 'or', 'non', '-', 'christian', 'you', 'will', 'not', 'be', 'comfortable', '.']...]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorText([   2,    8,   62,   85,   38,   97,   56,  684, 2965,   27])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = Numericalize()\n",
    "num.setup(toks)\n",
    "nums = toks.map(num)\n",
    "nums[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorText([   2,    8,   62,   85,   38,   97,   56,  684, 2965,   27,   24,  366, 1459,   51,   62,  500,  266,   49,   12,  980,  173,   73,   54,   77,   47,  139, 4488,   21,    9,   27,   85,   38,\n",
       "         590,   73,   12, 1033, 7891,   25, 1853,   24,   37,   42,   14,  151,    5,  141,   55,    8,    9,  257, 2966, 5004,   10,   57,   47, 2176,   19,    9,   27,  134,   56,  442,  453,  247,\n",
       "          14,   82,   10,   73,   13,  382, 1363,   50,   50,   73,   34,  196, 2487,   40, 2083,   87,   55,    8,    9,  111, 1777,   14,    9, 1460,   14,    8, 5678,    8, 1271,   13,    8, 4053,\n",
       "           8, 3172,   39,   37,   15,  555,    8,  853,    8, 4054,   36,   41,  324,  528,   19,   20, 2639,   27,   10,   26,    8,    9,  173,   73,    8,  608,    8, 4489,   11,  685,   28,   45,\n",
       "         107, 2177, 1364,  756, 2967, 6577,   11,    0,   11,  312,  652,   12,   82,   19,    8, 2640,   11,   13,    9,   83, 1365, 4055,  731,   73,   80, 1705,  142,  743,   29,    9,  102, 2488,\n",
       "         116,  267,   73,   88,  981,   34,   15,  256,   21,   34,   41,   19,   28,   56,  556,   82,   73,   30,  105,  500,   28,   69,  261,   11,   13,  242,  106,    0,   11,    9, 2178,  497,\n",
       "          73,   54,   23,   67, 5679,  818,   48, 1547,   13,  284,   73,  385,    0,   55,   55])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#10) ['xxbos','xxmaj','what','could','have','been','an','excellent','hostage','movie']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums_dec = num.decode(nums[0][:10]); nums_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos xxmaj what could have been an excellent hostage movie'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.decode(nums_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#207) ['xxbos','xxmaj','what','could','have','been','an','excellent','hostage','movie'...],\n",
       " (#528) ['xxbos','xxmaj','one','of','the','problems','with','popular','culture',','...])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok((txts[0], txts[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Your Own Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2.0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x:int): return x*1\n",
    "tfm = Transform(f)\n",
    "tfm(2),tfm(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2.0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@Transform\n",
    "def f(x:int): return x*1\n",
    "f(2),f(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x:int):\n",
    "    return x *2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HelloHello'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizeMean(Transform):\n",
    "    def setups(self, items): self.mean = sum(items)/len(items)\n",
    "    def encodes(self, x): return x-self.mean\n",
    "    def decodes(self, x): return x+self.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = NormalizeMean()\n",
    "tfm.setup([1,2,3,4,5])\n",
    "start = 2\n",
    "y = tfm(start)\n",
    "z = tfm.decode(y)\n",
    "tfm.mean,y,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([1,2,3,4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_transform = NormalizeMean()\n",
    "normalize_transform.setup([1,2,3,4,5,6])\n",
    "start = 2\n",
    "\n",
    "y = normalize_transform(start) # bascially encodes method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.5"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y # 2-3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = normalize_transform.decode(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_transform.mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorText([   2,    8,   62,   85,   38,   97,   56,  684, 2965,   27,   24,  366, 1459,   51,   62,  500,  266,   49,   12,  980])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tfms = Pipeline([tok, num])\n",
    "t = text_tfms(txts[0]); t[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos xxmaj what could have been an excellent hostage movie was totally ruined by what apparently lo'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tfms.decode(t)[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<kbd>Ctrl</kbd> + <kbd>Shift</kbd> + <kbd>-</kbd> will split the current cell into two from where your cursor is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfmdLists and Datasets: Transformed Collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfmdLists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tls = TfmdLists(files, [Tokenizer.from_folder(path), Numericalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tls[0]; t[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tls.decode(t)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tls.show(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = int(len(files)*0.8)\n",
    "splits = [list(range(cut)), list(range(cut,len(files)))]\n",
    "tls = TfmdLists(files, [Tokenizer.from_folder(path), Numericalize], \n",
    "                splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tls.valid[0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbls = files.map(parent_label)\n",
    "lbls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = Categorize()\n",
    "cat.setup(lbls)\n",
    "cat.vocab, cat(lbls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tls_y = TfmdLists(files, [parent_label, Categorize()])\n",
    "tls_y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tfms = [Tokenizer.from_folder(path), Numericalize]\n",
    "y_tfms = [parent_label, Categorize()]\n",
    "dsets = Datasets(files, [x_tfms, y_tfms])\n",
    "x,y = dsets[0]\n",
    "x[:20],y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tfms = [Tokenizer.from_folder(path), Numericalize]\n",
    "y_tfms = [parent_label, Categorize()]\n",
    "dsets = Datasets(files, [x_tfms, y_tfms], splits=splits)\n",
    "x,y = dsets.valid[0]\n",
    "x[:20],y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dsets.valid[0]\n",
    "dsets.decode(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dsets.dataloaders(bs=64, before_batch=pad_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [[Tokenizer.from_folder(path), Numericalize], [parent_label, Categorize]]\n",
    "files = get_text_files(path, folders = ['train', 'test'])\n",
    "splits = GrandparentSplitter(valid_name='test')(files)\n",
    "dsets = Datasets(files, tfms, splits=splits)\n",
    "dls = dsets.dataloaders(dl_type=SortedDL, before_batch=pad_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB)\n",
    "dls = DataBlock(\n",
    "    blocks=(TextBlock.from_folder(path),CategoryBlock),\n",
    "    get_y = parent_label,\n",
    "    get_items=partial(get_text_files, folders=['train', 'test']),\n",
    "    splitter=GrandparentSplitter(valid_name='test')\n",
    ").dataloaders(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the Mid-Level Data API: SiamesePair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "path = untar_data(URLs.PETS)\n",
    "files = get_image_files(path/\"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseImage(fastuple):\n",
    "    def show(self, ctx=None, **kwargs): \n",
    "        img1,img2,same_breed = self\n",
    "        if not isinstance(img1, Tensor):\n",
    "            if img2.size != img1.size: img2 = img2.resize(img1.size)\n",
    "            t1,t2 = tensor(img1),tensor(img2)\n",
    "            t1,t2 = t1.permute(2,0,1),t2.permute(2,0,1)\n",
    "        else: t1,t2 = img1,img2\n",
    "        line = t1.new_zeros(t1.shape[0], t1.shape[1], 10)\n",
    "        return show_image(torch.cat([t1,line,t2], dim=2), \n",
    "                          title=same_breed, ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = PILImage.create(files[0])\n",
    "s = SiameseImage(img, img, True)\n",
    "s.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = PILImage.create(files[1])\n",
    "s1 = SiameseImage(img, img1, False)\n",
    "s1.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = Resize(224)(s1)\n",
    "s2.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_func(fname):\n",
    "    return re.match(r'^(.*)_\\d+.jpg$', fname.name).groups()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseTransform(Transform):\n",
    "    def __init__(self, files, label_func, splits):\n",
    "        self.labels = files.map(label_func).unique()\n",
    "        self.lbl2files = {l: L(f for f in files if label_func(f) == l) \n",
    "                          for l in self.labels}\n",
    "        self.label_func = label_func\n",
    "        self.valid = {f: self._draw(f) for f in files[splits[1]]}\n",
    "        \n",
    "    def encodes(self, f):\n",
    "        f2,t = self.valid.get(f, self._draw(f))\n",
    "        img1,img2 = PILImage.create(f),PILImage.create(f2)\n",
    "        return SiameseImage(img1, img2, t)\n",
    "    \n",
    "    def _draw(self, f):\n",
    "        same = random.random() < 0.5\n",
    "        cls = self.label_func(f)\n",
    "        if not same: \n",
    "            cls = random.choice(L(l for l in self.labels if l != cls)) \n",
    "        return random.choice(self.lbl2files[cls]),same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = RandomSplitter()(files)\n",
    "tfm = SiameseTransform(files, label_func, splits)\n",
    "tfm(files[0]).show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tls = TfmdLists(files, tfm, splits=splits)\n",
    "show_at(tls.valid, 0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = tls.dataloaders(after_item=[Resize(224), ToTensor], \n",
    "    after_batch=[IntToFloatTensor, Normalize.from_stats(*imagenet_stats)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Why do we say that fastai has a \"layered\" API? What does it mean?\n",
    "1. Why does a `Transform` have a `decode` method? What does it do?\n",
    "1. Why does a `Transform` have a `setup` method? What does it do?\n",
    "1. How does a `Transform` work when called on a tuple?\n",
    "1. Which methods do you need to implement when writing your own `Transform`?\n",
    "1. Write a `Normalize` transform that fully normalizes items (subtract the mean and divide by the standard deviation of the dataset), and that can decode that behavior. Try not to peek!\n",
    "1. Write a `Transform` that does the numericalization of tokenized texts (it should set its vocab automatically from the dataset seen and have a `decode` method). Look at the source code of fastai if you need help.\n",
    "1. What is a `Pipeline`?\n",
    "1. What is a `TfmdLists`? \n",
    "1. What is a `Datasets`? How is it different from a `TfmdLists`?\n",
    "1. Why are `TfmdLists` and `Datasets` named with an \"s\"?\n",
    "1. How can you build a `DataLoaders` from a `TfmdLists` or a `Datasets`?\n",
    "1. How do you pass `item_tfms` and `batch_tfms` when building a `DataLoaders` from a `TfmdLists` or a `Datasets`?\n",
    "1. What do you need to do when you want to have your custom items work with methods like `show_batch` or `show_results`?\n",
    "1. Why can we easily apply fastai data augmentation transforms to the `SiamesePair` we built?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use the mid-level API to prepare the data in `DataLoaders` on your own datasets. Try this with the Pet dataset and the Adult dataset from Chapter 1.\n",
    "1. Look at the Siamese tutorial in the fastai documentation to learn how to customize the behavior of `show_batch` and `show_results` for new type of items. Implement it in your own project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding fastai's Applications: Wrap Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations—you've completed all of the chapters in this book that cover the key practical parts of training models and using deep learning! You know how to use all of fastai's built-in applications, and how to customize them using the data block API and loss functions. You even know how to create a neural network from scratch, and train it! (And hopefully you now know some of the questions to ask to make sure your creations help improve society too.)\n",
    "\n",
    "The knowledge you already have is enough to create full working prototypes of many types of neural network applications. More importantly, it will help you understand the capabilities and limitations of deep learning models, and how to design a system that's well adapted to them.\n",
    "\n",
    "In the rest of this book we will be pulling apart those applications, piece by piece, to understand the foundations they are built on. This is important knowledge for a deep learning practitioner, because it is what allows you to inspect and debug models that you build and create new applications that are customized for your particular projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
